# A High-Resolution Canopy Height Model using a Deep Learning Approach

This repository contains the implementation of a deep learning framework designed to estimate forest canopy height from RGB aerial imagery. By integrating **Hierarchical Vision Transformers (MiT-B5)** into a **U-Net** architecture, the model captures both local textures and global spatial contexts, achieving high precision in diverse forest ecosystems.

## ğŸš€ Key Results
* **Coefficient of Determination in the validation set ($R^2$):** 0.93
* **Training Dataset:** ~20,629 patches from the NEON network.
* **Spatial Resolution:** 1 meter per pixel.

## ğŸ› ï¸ Architecture
The core of this project is a hybrid encoder-decoder structure:
- **Encoder:** Mix Transformer (MiT-B5) - Provides a powerful hierarchical representation of forest patterns.
- **Decoder:** U-Net style upsampling to recover spatial resolution for precise height mapping.
- **Data Format:** Optimized HDF5 handling for big datasets (23k+ patches).
  
![PredicciÃ³n de Altura de Dosel](./assets/image_pred.png)


## ğŸ“ Repository Structure
```text
â”œâ”€â”€ assets/             # resources for the README.md
â”œâ”€â”€ data/               # Instructions for HDF5 dataset structure
â”œâ”€â”€ models/             # Architecture definition (MiT-B5 + U-Net)
â”œâ”€â”€ scripts/            # Training (train.py) and Inference (predict.py)
â”œâ”€â”€ test_images/        # Sample images and download instructions
â”œâ”€â”€ requirements.txt    # Required libraries (PyTorch, SMP, H5py)
â””â”€â”€ README.md           # Project documentation

